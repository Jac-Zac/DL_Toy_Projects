# Neural Representations and Backpropagation

This project is inspired by the seminal paper [*Learning Representations by Back-Propagating Errors*](https://jontallen.ece.illinois.edu/uploads/498-NS.S21/RumelhartHintonWilliams-BackPropError.86.pdf). You'll revisit core concepts from the course by reproducing Figure 1 from the paper using PyTorch, and analyzing the internal representations learned by a neural network.

---

## ğŸ“Œ Objectives

- ğŸ“– Read and reflect on the paper: *Rumelhart, Hinton & Williams (1986)*
- ğŸ§  Identify course concepts covered in the paper and in your implementation
- ğŸ” Reproduce Figure 1 using PyTorch
- ğŸ—£ï¸ Comment on:
  - Whether your results match the original (it's okay if they donâ€™t)
  - How to interpret the networkâ€™s learned representation

---

## ğŸš€ Quick Start

```bash
# View all options
python src/main.py --help

# Train a model from scratch
python src/main.py --model train

# Load a pre-trained model
python src/main.py --model load
```

## Folder Structure

Hereâ€™s a suggested folder structure for your project:

```bash
.
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ utils
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data.py
â”‚   â”‚   â”œâ”€â”€ environment.py
â”‚   â”‚   â””â”€â”€ plot.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ train_test.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
